
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8123341a-0bd6-4113-9063-04f6962fd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinforcement Learning tutorial for three-level population transfer\n",
    "# Copyright (C) 2022 Luigi Giannelli\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7941d328-50b4-4019-870c-1f3344653c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from qutip import basis, expect, ket2dm, mesolve\n",
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "tf.random.set_seed(12357111317)\n",
    "# tf.random.set_seed(123571113171923)\n",
    "from ThreeLS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e409177-84d4-45d3-b1f4-b20c46ccb99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce28e83-c592-4623-9646-c2614588e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if you want to force the not use of the GPU\n",
    "tf.config.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b2857-739f-4adf-8334-11957d4970df",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d05ecc9-e393-4a5e-95bf-54ada44e4456",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Hhm-5R7spVx"
   },
   "outputs": [],
   "source": [
    "Ωmax = 20\n",
    "n_steps = 30\n",
    "γ = 5\n",
    "T = 1\n",
    "reward_gain = 1.0\n",
    "\n",
    "fc_layer_params = (100, 50, 30)\n",
    "learning_rate = 1e-3\n",
    "\n",